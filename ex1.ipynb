{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from tpot.config.classifier_nn import classifier_config_nn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.config import classifier_config_dict_light\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_config = classifier_config_dict_light\n",
    "\n",
    "personal_config['sklearn.neural_network.MLPClassifier'] = {\n",
    "    # MLPClassifier for neural networks\n",
    "    # TODO: revisit/tweak: alpha, momentum, learning rate_init\n",
    "    # separater paras based on activation\n",
    "    'hidden_layer_sizes': [4],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n",
    "    'learning_rate_init': [1e-3, 1e-2, 1e-1, 0.5, 0.75, 0.9],\n",
    "    'momentum': [0.1, 0.5, 0.75, 0.9]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['with_null_5_nullfac_AAA_bench_mod_4_up_down_gb_svm_score_0.51229_62', 'with_null_5_nullfac_AAA_bench_mod_4_up_down_rf_lr2_score_0.58862_84', 'with_null_5_nullfac_AAA_bench_mod_4_up_down_dt_rf_score_0.3025_49', 'with_null_5_nullfac_AAA_bench_mod_4_up_down_svm_rf_score_0.03527_70', 'with_null_5_nullfac_AAA_bench_mod_4_up_down_lr2_dt_score_0.19388_33', 'with_null_5_nullfac_AAA_bench_mod_4_up_down_lr2_svm_score_0.10077_72', 'with_null_5_nullfac_AAA_bench_mod_4_up_down_gb_dt_score_0.23849_25', 'with_null_5_nullfac_AAA_bench_mod_4_up_down_lr2_dt_score_0.22989_91', 'with_null_5_nullfac_AAA_bench_mod_4_up_down_gb_knn_score_0.44186_7', 'with_null_5_nullfac_AAA_bench_mod_4_up_down_lr2_knn_score_0.14997_61']\n"
     ]
    }
   ],
   "source": [
    "path = ''\n",
    "extension = 'csv'\n",
    "data_dir = 'csv_data_300/'\n",
    "os.chdir(path + data_dir)\n",
    "data_sets = [i.replace(\".csv\", \"\") for i in glob.glob('*.{}'.format(extension))]\n",
    "print(data_sets[0:10])\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=110), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.5279115812554632\n",
      "Generation 2 - Current best internal CV score: 0.5332095945004963\n",
      "Generation 3 - Current best internal CV score: 0.534543046357616\n",
      "Generation 4 - Current best internal CV score: 0.5372008830022075\n",
      "Generation 5 - Current best internal CV score: 0.5372008830022075\n",
      "Generation 6 - Current best internal CV score: 0.5372008830022075\n",
      "Generation 7 - Current best internal CV score: 0.5385164377676045\n",
      "Generation 8 - Current best internal CV score: 0.5386498362890203\n",
      "Generation 9 - Current best internal CV score: 0.5386498362890203\n",
      "Generation 10 - Current best internal CV score: 0.5386498362890203\n",
      "\n",
      "Best pipeline: MLPClassifier(FeatureAgglomeration(SelectPercentile(input_matrix, percentile=97), affinity=manhattan, linkage=average), activation=tanh, alpha=1.0, hidden_layer_sizes=4, learning_rate=adaptive, learning_rate_init=0.5, momentum=0.5, solver=lbfgs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5975968b4d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0maccuracy_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimized_pipeline_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pipelines/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdat_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0maccuracy_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Training CV Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Testing Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "for dat_name in data_sets:\n",
    "    accuracy_ls = []\n",
    "    tpot_data = pd.read_csv(data_dir + dat_name + '.csv')\n",
    "    Xdata = tpot_data.loc[:, tpot_data.columns != 'Class']\n",
    "    Ydata = tpot_data['Class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata,\n",
    "                                                        train_size=0.75, test_size=0.25)\n",
    "\n",
    "    tpot = TPOTClassifier(generations=10, config_dict=personal_config,\n",
    "                          population_size=10, verbosity=2,\n",
    "                          template = 'Selector-Transformer-MLPClassifier')\n",
    "#     for i in range(10):\n",
    "    tpot.fit(X_train, y_train)\n",
    "    accuracy_ls.append([tpot._optimized_pipeline_score, tpot.score(X_test, y_test)])\n",
    "    tpot.export('pipelines/' + dat_name + '.py')\n",
    "\n",
    "    accuracy_mat = pd.DataFrame(accuracy_ls, columns = ['Training CV Accuracy', 'Testing Accuracy'])\n",
    "    accuracy_mat.to_csv(\"accuracies/\" + dat_name + \".tsv\", sep = \"\\t\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path + data_dir)\n",
    "print(glob.glob('*.{}'.format(extension)))\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tpot_data = pd.read_csv(\n",
    "#     'datasets/AAA_bench_mod_4_up_down_dt_svm_score_0.5538_60.txt', sep=\"\\t\")\n",
    "# tpot_data = pd.read_csv(\n",
    "#     'datasets/with_null_AAA_bench_mod_4_up_down_dt_gb_score_0.35173_75.csv')\n",
    "# Xdata = tpot_data.loc[:, tpot_data.columns != 'Class']\n",
    "# Xdata = Xdata.drop(['Fitness', 'Distribution'], axis=1)\n",
    "# Ydata = tpot_data['Class']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(Xdata, Ydata,\n",
    "#                                                     train_size=0.75, test_size=0.25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tpot = TPOTClassifier(generations=10, config_dict=personal_config,\n",
    "#                       population_size=10, verbosity=2,\n",
    "#                       template='Selector-Transformer-MLPClassifier')\n",
    "# tpot.fit(X_train, y_train)\n",
    "# print(tpot.score(X_test, y_test))\n",
    "\n",
    "# tpot.export('tpot_light_dt_gb_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
